<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Feedforward Backpropagation</title>
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
        </script>
        <script async
                src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"
                type="text/javascript">
        </script>
        </head>
    </head>
    <body>
        <section>
            <h2>Introduction</h2>
            <p>
                The most common algorithm for training neural networks is backpropagation.

                This approach uses the <a href="../General/ChainRule.html">chain rule</a> to compute the partial
                derivative of the cost $\mathcal{J}$ with respect to each parameter, i.e.
                $\partial \mathcal{J} / \partial W^{l}_{ji}$ and $\partial \mathcal{J} / \partial b^{l}_{j}$ for all
                weights $W^{l}_{ji}$ and biases $b^{l}_{j}$.

                The parameters are then adjusted as required to minimise the cost $\mathcal{J}$.

                As the cost surface is likely to be non-convex, there is no guarantee that a global minimum will be
                reached, and therefore optimisation heuristics based on gradient descent are often used instead.
            </p>
        </section>
        <section>
            <h2>Intuition</h2>
            <p>
                Given a neural network, making a small change $\Delta W^{l}_{ji}$ to the weight of edge $W^{l}_{ji}$
                will result in a corresponding change in the output $\mathbf{h}^{l}_{j}$ of the target neuron of the
                edge.

                Assuming a fully connected network, this change will affect all outputs $\mathbf{h}^{l+1}$ of the
                neurons in the next layer.

                This repeats as the change propagates through the network until it reaches the output $\mathbf{h}^L$ of
                the neurons in the output layer of the network, and consequently causes a change in the cost
                $\mathcal{J}$.

                Ignoring biases, the changes can be related through
                $\Delta \mathcal{J} \approx \frac{\partial \mathcal{J}}{\partial W^{l}_{ji}} \Delta W^{l}_{ji}$, i.e.
                the change in the cost is approximately equal to the change in the cost with respect to a change in
                the weight multiplied by the actual change in the weight's value.

                One way to calculate $\partial \mathcal{J} / \partial W^{l}_{ji}$ is to follow the small perturbations
                caused by $\Delta W^{l}_{ji}$ until we reach $\mathcal{J}$.

                Concentrating on one neuron in each layer and ignoring biases, $\Delta W^{l}_{ji}$ causes a change
                $\Delta \mathbf{h}^{l}_{j}$ in the output of the $j$th neuron in the $l$th layer.

                This change is given by:
                $$
                    \Delta \mathbf{h}^{l}_{j} \approx
                        \frac{\partial \mathbf{h}^{l}_{j}}{\partial W^{l}_{ji}}
                        \Delta W^{l}_{ji}
                $$

                Taking one neuron in layer $l+1$ affected by this change in $\mathbf{h}^{l}_{j}$ gives:
                $$
                    \begin{align}
                    \Delta \mathbf{h}^{l+1}_{k} & \approx
                        \frac{\partial \mathbf{h}^{l+1}_{k}}{\partial \mathbf{h}^{l}_{j}}
                        \Delta \mathbf{h}^{l}_{j}
                    \\
                    \Delta \mathbf{h}^{l+1}_{k} & \approx
                        \frac{\partial \mathbf{h}^{l+1}_{k}}{\partial \mathbf{h}^{l}_{j}}
                        \frac{\partial \mathbf{h}^{l}_{j}}{\partial W^{l}_{ji}}
                        \Delta W^{l}_{ji}
                    \end{align}
                $$

                Propagating this to the output of the network gives:
                $$
                    \Delta \mathcal{J} \approx
                        \frac{\partial \mathcal{J}}{\partial \mathbf{h}^{L}_{z}}
                        \frac{\partial \mathbf{h}^{L}_{z}}{\partial \mathbf{h}^{L-1}_{y}}
                        \frac{\partial \mathbf{h}^{L-1}_{y}}{\partial \mathbf{h}^{L-2}_{x}}
                        \ldots
                        \frac{\partial \mathbf{h}^{l+1}_{k}}{\partial \mathbf{h}^{l}_{j}}
                        \frac{\partial \mathbf{h}^{l}_{j}}{\partial W^{l}_{ji}}
                        \Delta W^{l}_{ji}
                $$

                In order to get the entire change in the cost $\mathcal{J}$ caused by the change $\Delta W^{l}_{ji}$ it
                is necessary to sum over all paths from $W^{l}_{ji}$ to $\mathcal{J}$ as:
                $$
                    \Delta \mathcal{J} \approx
                        \sum_{zyx..k}
                            \frac{\partial \mathcal{J}}{\partial \mathbf{h}^{L}_{z}}
                            \frac{\partial \mathbf{h}^{L}_{z}}{\partial \mathbf{h}^{L-1}_{y}}
                            \frac{\partial \mathbf{h}^{L-1}_{y}}{\partial \mathbf{h}^{L-2}_{x}}
                            \ldots
                            \frac{\partial \mathbf{h}^{l+1}_{k}}{\partial \mathbf{h}^{l}_{j}}
                            \frac{\partial \mathbf{h}^{l}_{j}}{\partial W^{l}_{ji}}
                            \Delta W^{l}_{ji}
                $$

                Substituting this into
                $\Delta \mathcal{J} \approx \frac{\partial \mathcal{J}}{\partial W^{l}_{ji}} \Delta W^{l}_{ji}$ gives:
                $$
                    \frac{\partial \mathcal{J}}{\partial W^{l}_{ji}} \approx
                        \sum_{zyx..k}
                            \frac{\partial \mathcal{J}}{\partial \mathbf{h}^{L}_{z}}
                            \frac{\partial \mathbf{h}^{L}_{z}}{\partial \mathbf{h}^{L-1}_{y}}
                            \frac{\partial \mathbf{h}^{L-1}_{y}}{\partial \mathbf{h}^{L-2}_{x}}
                            \ldots
                            \frac{\partial \mathbf{h}^{l+1}_{k}}{\partial \mathbf{h}^{l}_{j}}
                            \frac{\partial \mathbf{h}^{l}_{j}}{\partial W^{l}_{ji}}
                $$

                What this tells us is that each edge in the network is associated with a rate, which is just
                the partial derivative of the target neuron's output with respect to the source neuron's output, i.e.
                $\partial \mathbf{h}^{l+1}_{j} / \partial \mathbf{h}^{l}_{i}$.

                The rate along a path between neurons is then just the product of the rates of the edges that make up
                the path, and the total rate between two neurons in the network is just the sum of the rates along all
                paths between the two.

                Now that we have the gradient of the cost $\mathcal{J}$ with respect to any weight in the network, we
                can determine how to change the weight in order to minimise $\mathcal{J}$.
            </p>
            <img src="../Images/Feedforward/BackpropIntuition.png">
        </section>
        <section>
        </section>




    <p>
        Commonly, neural networks are trained via stochastic gradient descent (SGD) using mini-batches, or one of its
        many variants. With a batch size of one, the SGD update rule is
        $$\mathbf{w} \leftarrow \mathbf{w} - \eta\nabla_{w}F_i$$
        where $\eta$ is the learning rate and $\nabla_{w}F_i$ the gradient of the objective function with respect to
        the parameters $\mathbf{w}$ as calculated on a single example $(x_i, y_i)$. The learning rate can be fixed, as
        in vanilla SGD, or adaptively tuned, as in the popular variants
        <a href="../General/Optimisation.html#AdaGrad">AdaGrad</a>,
        <a href="../General/Optimisation.html#AdaDelta">AdaDelta</a>,
        <a href="../General/Optimisation.html#RMSprop">RMSprop</a> and
        <a href="../General/Optimisation.html#Adam">Adam</a>.
    </p>
    <p>
        To calculate the gradient in a feedforward network, backpropagation proceeds through a forward and backward
        pass. In the forward pass an example (or mini-batch) is propogated through the network to produce a value
        $v_j$ at each node and outputs $\hat{\mathbf{y}}$ at the final/top layer. Next the loss
        $\mathcal{L}(\hat{y}_k, y_k)$ is calcualted at each output node $k$. For each output node $k$ we then calculate
        $$\delta_k = \frac{\partial \mathcal{L}(\hat{y}_k, y_k)}{\partial \hat{y}_k} \cdot l'_k(a_k).$$
        Given the $\delta_j$ values for each node in the layer following/above node $i$ such that tere is an edge from
        $i$ to $j$, we calculate
        $$\delta_i = l'_i(a_i) \sum_{j} \delta_j \cdot w_{ji}.$$
        Each value $\delta_i$ represents the derivative $\partial \mathcal{L} / \partial a_i$ of the total loss of the
        network with respect to node $i$'s incoming activation. Given the values $v_i$ calcualted during the forward
        pass and the values $\delta_j$ calculated during the backward pass, the derivative of the loss function
        $\mathcal{L}$ with resect to the weight parameter $w_{ji}$ is
        $$\frac{\partial \mathcal{L}}{\partial w_{ji}} = \delta_j v_i.$$
    </p>
    <p>Uncited References</p>
    <ul>
        <li>
            <a href="../References.html#critReviewOfRNNs">
                A Critical Review of Recurrent Neural Networks for Sequence Learning
            </a>
        </li>
    </ul>
    </body>
</html>